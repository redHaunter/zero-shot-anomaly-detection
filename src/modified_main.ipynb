{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import wide_resnet50_2\n",
    "import datasets.mvtec as mvtec\n",
    "from einops import rearrange\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pwd= /home/redha/Desktop/Projects/zeroshot/code/src\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print('pwd=', os.getcwd())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model_number = 3\n",
    "get_feature_model_number = 2\n",
    "calc_score_model_number = 2\n",
    "input_model_number = 2 #320*320 -> model_number = 1, 1024*1024 -> model_number = 2\n",
    "get_arrange_model_number = input_model_number\n",
    "project_path = \"/home/redha/Desktop/Projects/zeroshot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_number):\n",
    "\n",
    "    if model_number == 1:\n",
    "        return wide_resnet50_2(pretrained=True, progress=True)\n",
    "    \n",
    "    elif model_number == 2:\n",
    "        resnet50_model = wide_resnet50_2(pretrained=True, progress=True)\n",
    "        layers = list(resnet50_model.children())[:6]\n",
    "        del layers[4][0].downsample\n",
    "        del layers[5][0].downsample\n",
    "\n",
    "        for bottleneck_1 in layers[4]:\n",
    "            bottleneck_1.conv1.out_channels = 64\n",
    "            bottleneck_1.bn1.num_features = 64\n",
    "            bottleneck_1.conv2.in_channels = 64\n",
    "            bottleneck_1.conv2.out_channels = 64\n",
    "            bottleneck_1.bn2.num_features = 64\n",
    "            bottleneck_1.conv3.in_channels = 64\n",
    "\n",
    "        for bottleneck_2 in layers[5]:\n",
    "            bottleneck_2.conv1.out_channels = 128\n",
    "            bottleneck_2.bn1.num_features = 128\n",
    "            bottleneck_2.conv2.in_channels = 128\n",
    "            bottleneck_2.conv2.out_channels = 128\n",
    "            bottleneck_2.bn2.num_features = 128\n",
    "            bottleneck_2.conv3.in_channels = 128\n",
    "            bottleneck_2.conv3.out_channels = 512\n",
    "            bottleneck_2.bn3.num_features = 512\n",
    "\n",
    "        model = nn.Sequential(*layers)\n",
    "        return model\n",
    "    \n",
    "    elif model_number == 3:\n",
    "        resnet50_model = wide_resnet50_2(pretrained=True, progress=True)\n",
    "        layers = list(resnet50_model.children())[:6]\n",
    "        model = nn.Sequential(*layers)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(model, img, device, outputs):\n",
    "\n",
    "    if get_feature_model_number == 1:\n",
    "        with torch.no_grad():\n",
    "            _ = model(img.to(device))\n",
    "\n",
    "        layer2_feature = outputs[-1]\n",
    "\n",
    "        outputs.clear()\n",
    "        return [layer2_feature]\n",
    "    \n",
    "    elif get_feature_model_number == 2:\n",
    "        with torch.no_grad():\n",
    "            features = model(img.to(device))\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  calc_score(test, gallery, layerID):\n",
    "\n",
    "    if calc_score_model_number == 1:\n",
    "        heatmap = np.zeros((test.shape[0], test.shape[2]))\n",
    "        for imgID in range(test.shape[0]):\n",
    "            nbrs = NearestNeighbors(n_neighbors=400, algorithm='ball_tree').fit(gallery[imgID, layerID, :, :])\n",
    "            distances, _ = nbrs.kneighbors(test[imgID, layerID, :, :])\n",
    "            heatmap[imgID, :] = np.mean(distances, axis=1)\n",
    "            heatmap = torch.from_numpy(heatmap.astype(np.float32)).clone()\n",
    "        dim = int(np.sqrt(test.shape[2]))\n",
    "        return heatmap.reshape(test.shape[0], dim, -1)\n",
    "    \n",
    "    elif calc_score_model_number == 2:\n",
    "        heatmap = np.zeros((test.shape[0], test.shape[2]))\n",
    "        featureMean = np.mean(test, axis=2)\n",
    "\n",
    "        for imgID in range(test.shape[0]):\n",
    "            for fID in range(test.shape[2]):\n",
    "                heatmap[imgID,fID] = np.linalg.norm(test[imgID, layerID,fID,:]-featureMean)\n",
    "\n",
    "        dim = int(np.sqrt(test.shape[2]))\n",
    "        return torch.from_numpy(heatmap.reshape(test.shape[0], dim, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rearrange(features):\n",
    "    m = torch.nn.AvgPool2d(3, 1, 1)\n",
    "    if get_arrange_model_number == 1:\n",
    "        return rearrange(m(features[0]), 'i c h w ->i  (h w) c').unsqueeze(1).to('cpu').detach().numpy().copy()\n",
    "    elif get_arrange_model_number == 2:\n",
    "        return rearrange(m(features[0]), 'c h w ->1 (h w) c').unsqueeze(1).to('cpu').detach().numpy().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_scoremap(imgID, heatMap, cut,imgshape):\n",
    "    blank = torch.ones_like(heatMap[imgID, :, :]) * heatMap[imgID, :, :].min()\n",
    "    blank[cut:heatMap.shape[1] - cut, cut:heatMap.shape[1] - cut] = heatMap[imgID, cut:heatMap.shape[1] - cut,\n",
    "                                                                    cut:heatMap.shape[1] - cut]\n",
    "    return F.interpolate(blank[:, :].unsqueeze(0).unsqueeze(0), size=imgshape, mode='bilinear', align_corners=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalization(x):\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    x = (((x.transpose(1, 2, 0) * std) + mean) * 255.).astype(np.uint8)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loc_result(test_imgs, gt_mask_list, score_map_list, threshold,\n",
    "                         save_path, class_name, vis_num,cut_pixel):\n",
    "    for t_idx in range(vis_num):\n",
    "        test_img = test_imgs[t_idx]\n",
    "        test_img = denormalization(test_img)\n",
    "        test_gt = gt_mask_list[t_idx].transpose(1, 2, 0).squeeze()\n",
    "        heat = score_map_list[t_idx].flatten(0, 2).cpu().detach().numpy().copy()\n",
    "        test_pred = score_map_list[t_idx].flatten(0, 2).cpu().detach().numpy()\n",
    "        test_pred[test_pred <= threshold] = 0\n",
    "        test_pred[test_pred > threshold] = 1\n",
    "        test_pred_img = test_img.copy()\n",
    "        test_pred_img =test_pred_img[cut_pixel:test_img.shape[0]-cut_pixel,cut_pixel:test_img.shape[0]-cut_pixel, :]\n",
    "        test_pred_img[test_pred == 0] = 0\n",
    "\n",
    "        fig_img, ax_img = plt.subplots(1, 4, figsize=(12, 4))\n",
    "        fig_img.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "\n",
    "        for ax_i in ax_img:\n",
    "            ax_i.axes.xaxis.set_visible(False)\n",
    "            ax_i.axes.yaxis.set_visible(False)\n",
    "\n",
    "        ax_img[0].imshow(test_img)\n",
    "        ax_img[0].title.set_text('Image')\n",
    "        ax_img[1].imshow(test_gt, cmap='gray')\n",
    "        ax_img[1].title.set_text('GroundTruth')\n",
    "        ax_img[2].imshow(heat)\n",
    "        ax_img[2].title.set_text('HeatMap')\n",
    "        ax_img[3].imshow(test_pred_img)\n",
    "        ax_img[3].title.set_text('Predicted anomalous image')\n",
    "\n",
    "        os.makedirs(os.path.join(save_path, 'images'), exist_ok=True)\n",
    "        fig_img.savefig(os.path.join(save_path, 'images', '%s_%03d.png' % (class_name, t_idx)), dpi=100)\n",
    "        fig_img.clf()\n",
    "        plt.close(fig_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_number)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "outputs = []\n",
    "if model_number == 1:\n",
    "    def hook(module, input, output):\n",
    "        outputs.append(output)\n",
    "\n",
    "    model.layer2.register_forward_hook(hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| feature extraction | test |:  66%|██████▌   | 52/79 [00:34<00:23,  1.15it/s]"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "fig_img_rocauc = ax[0]\n",
    "fig_pixel_rocauc = ax[1]\n",
    "\n",
    "total_roc_auc = []\n",
    "total_pixel_roc_auc = []\n",
    "avg_calc_per_image = []\n",
    "\n",
    "for class_name in mvtec.CLASS_NAMES:\n",
    "    if input_model_number == 1:\n",
    "        test_dataset = mvtec.MVTecDataset(class_name=class_name, is_train=False)\n",
    "    elif input_model_number == 2:\n",
    "        test_dataset = mvtec.MVTecDataset(class_name=class_name, is_train=False, cropsize=1024, to_change=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1, pin_memory=True)\n",
    "\n",
    "    gt_list = []\n",
    "    gt_mask_list = []\n",
    "    test_imgs = []\n",
    "    score_map_list = []\n",
    "    scores = []\n",
    "    cut_surrounding = 32\n",
    "    \n",
    "    started_time = datetime.datetime.now()\n",
    "    for (x, y, mask) in tqdm(test_dataloader, '| feature extraction | test |'):\n",
    "\n",
    "        test_imgs.extend(x.cpu().detach().numpy())\n",
    "        gt_list.extend(y.cpu().detach().numpy())\n",
    "        gt_mask_list.extend(mask[:, :, cut_surrounding:x.shape[2] - cut_surrounding,\n",
    "                            cut_surrounding:x.shape[2] - cut_surrounding].cpu().detach().numpy().astype(int))\n",
    "\n",
    "        features = get_feature(model, x, device, outputs)\n",
    "\n",
    "        gallery2 = get_rearrange(features)\n",
    "        heatMap2 = calc_score(gallery2, gallery2, 0)\n",
    "\n",
    "        for imgID in range(x.shape[0]):\n",
    "            cut2 = 3\n",
    "            newHeat = interpolate_scoremap(imgID, heatMap2, cut2, x.shape[2])\n",
    "            newHeat = gaussian_filter(newHeat.squeeze().cpu().detach().numpy(), sigma=4)\n",
    "            newHeat = torch.from_numpy(newHeat.astype(np.float32)).clone().unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "            score_map_list.append(newHeat[:, :, cut_surrounding:x.shape[2]-cut_surrounding,\n",
    "                                    cut_surrounding:x.shape[2] - cut_surrounding])\n",
    "            scores.append(score_map_list[-1].max().item())\n",
    "\n",
    "        del features\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    #calculate average time\n",
    "    finished_time = datetime.datetime.now()\n",
    "    avg_calc_per_image.append(((finished_time.minute - started_time.minute) * 60 + (finished_time.second - started_time.second))/len(test_dataloader))\n",
    "    # calculate image-level ROC AUC score\n",
    "    fpr, tpr, _ = roc_curve(gt_list, scores)\n",
    "    roc_auc = roc_auc_score(gt_list, scores)\n",
    "    total_roc_auc.append(roc_auc)\n",
    "    print('%s ROCAUC: %.3f' % (class_name, roc_auc))\n",
    "    fig_img_rocauc.plot(fpr, tpr, label='%s ROCAUC: %.3f' % (class_name, roc_auc))\n",
    "    # calculate per-pixel level ROCAUC\n",
    "    flatten_gt_mask_list = np.concatenate(gt_mask_list).ravel()\n",
    "    flatten_score_map_list = np.concatenate(score_map_list).ravel()\n",
    "\n",
    "    if input_model_number == 1:\n",
    "        fpr, tpr, _ = roc_curve(flatten_gt_mask_list, flatten_score_map_list)\n",
    "        per_pixel_rocauc = roc_auc_score(flatten_gt_mask_list, flatten_score_map_list)\n",
    "        total_pixel_roc_auc.append(per_pixel_rocauc)\n",
    "        print('%s pixel ROCAUC: %.3f' % (class_name, per_pixel_rocauc))\n",
    "        fig_pixel_rocauc.plot(fpr, tpr, label='%s ROCAUC: %.3f' % (class_name, per_pixel_rocauc))\n",
    "\n",
    "    # get optimal threshold\n",
    "    precision, recall, thresholds = precision_recall_curve(flatten_gt_mask_list, flatten_score_map_list)\n",
    "    a = 2 * precision * recall\n",
    "    b = precision + recall\n",
    "    f1 = np.divide(a, b, out=np.zeros_like(a), where=b != 0)\n",
    "    threshold = thresholds[np.argmax(f1)]\n",
    "\n",
    "    # visualize localization result\n",
    "    visualize_loc_result(test_imgs, gt_mask_list, score_map_list, threshold, project_path+\"/result\", class_name, 5,\n",
    "                            cut_surrounding)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(project_path+\"/result\", 'roc_curve.png'), dpi=100)\n",
    "    \n",
    "    \n",
    "print(avg_calc_per_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
